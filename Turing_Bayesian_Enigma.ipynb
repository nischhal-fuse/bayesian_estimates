{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d9228a5a",
   "metadata": {},
   "source": [
    "\n",
    "# üîê Cracking Enigma the Way Turing Did\n",
    "## Bayesian Inference, Log-Odds, and the Bombe ‚Äî in Python\n",
    "\n",
    "This notebook upgrades our Enigma simulation to be **historically faithful**:\n",
    "\n",
    "‚úÖ Log-odds scoring (Turing's Banburismus idea)  \n",
    "‚úÖ Multiple intercepted messages (sequential Bayes)  \n",
    "‚úÖ English language likelihood model  \n",
    "‚úÖ Live animation of belief collapse  \n",
    "\n",
    "This is *exactly* how probability defeated brute force.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13f04f53",
   "metadata": {},
   "source": [
    "\n",
    "## 1. Enigma Machine (Rotors + Reflector)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8063d3e2",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.12.3' requires the ipykernel package.\n",
      "\u001b[1;31m<a href='command:jupyter.createPythonEnvAndSelectController'>Create a Python Environment</a> with the required packages.\n",
      "\u001b[1;31mOr install 'ipykernel' using the command: '/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "import string\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.animation import FuncAnimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b248aaca",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import string\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.animation import FuncAnimation\n",
    "\n",
    "ALPHABET = string.ascii_uppercase\n",
    "A2I = {c:i for i,c in enumerate(ALPHABET)}\n",
    "I2A = {i:c for i,c in enumerate(ALPHABET)}\n",
    "\n",
    "ROTOR_I   = \"EKMFLGDQVZNTOWYHXUSPAIBRCJ\"\n",
    "ROTOR_II  = \"AJDKSIRUXBLHWTMCQGZNPYFVOE\"\n",
    "ROTOR_III = \"BDFHJLCPRTXVZNYEIWGAKMUSQO\"\n",
    "REFLECTOR = \"YRUHQSLDPXNGOKMIEBFZCWVJAT\"\n",
    "\n",
    "rotors = [ROTOR_I, ROTOR_II, ROTOR_III]\n",
    "\n",
    "def enigma_encrypt(text, positions):\n",
    "    pos = positions.copy()\n",
    "    out = \"\"\n",
    "    \n",
    "    for ch in text.upper():\n",
    "        if ch not in ALPHABET:\n",
    "            out += ch\n",
    "            continue\n",
    "        \n",
    "        pos[0] = (pos[0] + 1) % 26\n",
    "        if pos[0] == 0:\n",
    "            pos[1] = (pos[1] + 1) % 26\n",
    "        if pos[1] == 0:\n",
    "            pos[2] = (pos[2] + 1) % 26\n",
    "        \n",
    "        c = A2I[ch]\n",
    "        for i in range(3):\n",
    "            c = (A2I[rotors[i][(c + pos[i]) % 26]] - pos[i]) % 26\n",
    "        \n",
    "        c = A2I[REFLECTOR[c]]\n",
    "        \n",
    "        for i in reversed(range(3)):\n",
    "            c = (rotors[i].index(I2A[(c + pos[i]) % 26]) - pos[i]) % 26\n",
    "        \n",
    "        out += I2A[c]\n",
    "    \n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c2e44ce",
   "metadata": {},
   "source": [
    "\n",
    "## 2. English Language Model (Likelihood)\n",
    "\n",
    "Instead of keyword matching, we score decrypted text using\n",
    "**English letter frequencies**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78419017",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "english_freq = {\n",
    "    'E':0.127, 'T':0.091, 'A':0.082, 'O':0.075, 'I':0.070, 'N':0.067,\n",
    "    'R':0.060, 'S':0.063, 'H':0.061, 'L':0.040, 'D':0.043, 'C':0.028,\n",
    "    'U':0.028, 'M':0.024, 'F':0.022, 'Y':0.020, 'W':0.024, 'G':0.020,\n",
    "    'P':0.019, 'B':0.015, 'V':0.010, 'K':0.008, 'X':0.002,\n",
    "    'Q':0.001, 'J':0.002, 'Z':0.001\n",
    "}\n",
    "\n",
    "def english_log_likelihood(text):\n",
    "    ll = 0.0\n",
    "    for ch in text:\n",
    "        if ch in english_freq:\n",
    "            ll += np.log(english_freq[ch])\n",
    "    return ll\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "718722b6",
   "metadata": {},
   "source": [
    "\n",
    "## 3. Intercepted Messages (Sequential Bayes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61982517",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "true_key = [3, 14, 7]\n",
    "\n",
    "messages = [\n",
    "    \"WEATHER REPORT FROM ATLANTIC\",\n",
    "    \"WEATHER CONDITIONS STABLE\",\n",
    "    \"REPORT SENT AT DAWN\"\n",
    "]\n",
    "\n",
    "ciphertexts = [enigma_encrypt(m, true_key) for m in messages]\n",
    "ciphertexts\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acfd9cb5",
   "metadata": {},
   "source": [
    "\n",
    "## 4. Hypothesis Space & Log-Odds (Turing Score)\n",
    "\n",
    "We maintain **log-posteriors** instead of probabilities.\n",
    "This avoids underflow and mirrors Turing's scoring system.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34c41abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "keys = [(a,b,c) for a in range(6) for b in range(6) for c in range(6)]\n",
    "log_post = np.zeros(len(keys))  # uniform prior in log-space\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "124e7e6a",
   "metadata": {},
   "source": [
    "\n",
    "## 5. Sequential Bayesian Updates\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09589b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "history = []\n",
    "\n",
    "for ct in ciphertexts:\n",
    "    for i, key in enumerate(keys):\n",
    "        decrypted = enigma_encrypt(ct, list(key))\n",
    "        log_post[i] += english_log_likelihood(decrypted)\n",
    "    \n",
    "    # normalize for numerical stability\n",
    "    log_post -= np.max(log_post)\n",
    "    probs = np.exp(log_post)\n",
    "    probs /= probs.sum()\n",
    "    history.append(probs.copy())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeacfd80",
   "metadata": {},
   "source": [
    "\n",
    "## 6. Final Result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46f47a4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "best_idx = np.argmax(history[-1])\n",
    "best_key = keys[best_idx]\n",
    "\n",
    "print(\"Recovered key:\", best_key)\n",
    "print(\"Decrypted final message:\")\n",
    "print(enigma_encrypt(ciphertexts[-1], list(best_key)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e366b40",
   "metadata": {},
   "source": [
    "\n",
    "## 7. Live Animation ‚Äî The Bombe in Action\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9068698c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig, ax = plt.subplots()\n",
    "bars = ax.bar(range(len(keys)), history[0])\n",
    "ax.set_ylim(0, max(history[-1])*1.1)\n",
    "ax.set_title(\"Bayesian Belief Over Enigma Keys\")\n",
    "\n",
    "def update(frame):\n",
    "    for bar, p in zip(bars, history[frame]):\n",
    "        bar.set_height(p)\n",
    "    ax.set_xlabel(f\"Intercept {frame+1}\")\n",
    "    return bars\n",
    "\n",
    "ani = FuncAnimation(fig, update, frames=len(history), interval=1200)\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
